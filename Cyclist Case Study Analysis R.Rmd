---
title: "Cyclist Case Study"
author: "Abhay Dhupar"
date: "2023-07-30"
output: html_document
---

### Install the required packages  
* Tidyverse for data import and wrangling  
* Lubridate for data functions  
* ggplot for visualization

```{r Loading libraries}
library(tidyverse)
library(lubridate)
library(ggplot2)
```

Checking the working directory and load desired path
```{r Checking the Working directory}
getwd() #displays working directory
```

### Step-1 : COLLECT DATA
Uploading Divvy Datasets here
```{r Uploading datasets}
setwd("C:/Users/abhay/OneDrive/Desktop/Google Data Analytics/Capstone Project - Cyclist/Divvy Quarter data") # path where data resides
q2_2019 <- read_csv('Divvy_Trips_2019_Q2.csv')
q3_2019 <- read_csv('Divvy_Trips_2019_Q3.csv')
q4_2019 <- read_csv('Divvy_Trips_2019_Q4.csv')
q1_2020 <- read_csv('Divvy_Trips_2020_Q1.csv')
```


### Step-2 : WRANGLE DATA AND COMBINE INTO A SINGLE FILE

Compare column names each of the files  
While the names don't have to be in the same order, they DO need to match perfectly before we can use a command to join them into one file

```{r checking column names}
colnames(q2_2019)
colnames(q3_2019)
colnames(q4_2019)
colnames(q1_2020)
```

Renaming columns to make them consistent with q1_2020
```{r Renaming columns to same name}
(q4_2019 <- rename(q4_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))

(q3_2019 <- rename(q3_2019
                   ,ride_id = trip_id
                   ,rideable_type = bikeid 
                   ,started_at = start_time  
                   ,ended_at = end_time  
                   ,start_station_name = from_station_name 
                   ,start_station_id = from_station_id 
                   ,end_station_name = to_station_name 
                   ,end_station_id = to_station_id 
                   ,member_casual = usertype))

(q2_2019 <- rename(q2_2019
                   ,ride_id = "01 - Rental Details Rental ID"
                   ,rideable_type = "01 - Rental Details Bike ID" 
                   ,started_at = "01 - Rental Details Local Start Time"  
                   ,ended_at = "01 - Rental Details Local End Time"  
                   ,start_station_name = "03 - Rental Start Station Name" 
                   ,start_station_id = "03 - Rental Start Station ID"
                   ,end_station_name = "02 - Rental End Station Name" 
                   ,end_station_id = "02 - Rental End Station ID"
                   ,member_casual = "User Type"))

```

Inspect the dataframe and look for incongruencies

```{r Inspecting data types}
str(q1_2020)
str(q4_2019)
str(q3_2019)
str(q2_2019)
```
Convert ride_id and rideable_type to character so they can stack correctly
```{r Converting types of ride_id and rideable_type to char}
q4_2019 <-  mutate(q4_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q3_2019 <-  mutate(q3_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
q2_2019 <-  mutate(q2_2019, ride_id = as.character(ride_id)
                   ,rideable_type = as.character(rideable_type)) 
```


Now Stack individual quarter's data frames into one big data frame

```{r Combining Dataframes}
all_trips <- bind_rows(q2_2019, q3_2019, q4_2019, q1_2020)
```

Remove lat, long, birthyear, and gender fields as this data was dropped beginning in 2020
```{r Removing columns we do not want}
all_trips <- all_trips %>%  
  select(-c(start_lat, start_lng, end_lat, end_lng, birthyear, gender, "01 - Rental Details Duration In Seconds Uncapped", "05 - Member Details Member Birthday Year", "Member Gender", "tripduration"))
```


### Step-3 : CLEAN UP AND PREPARE DATA FOR ANALYSIS

Inspect the new table that has been created
```{r new table preview}
colnames(all_trips)  #List of column names
nrow(all_trips)  #How many rows are in data frame?
dim(all_trips)  #Dimensions of the data frame?
head(all_trips)  #See the first 6 rows of data frame.  Also tail(all_trips)
str(all_trips)  #See list of columns and data types (numeric, character, etc)
summary(all_trips)  #Statistical summary of data. Mainly for numerics
```

There are a few problems we will need to fix:  
1.In the "member_casual" column, there are two names for members ("member" and "Subscriber") and two names for casual riders ("Customer" and "casual"). We will need to consolidate that from four to two labels.  
2.The data can only be aggregated at the ride-level, which is too granular. We will want to add some additional columns of data -- such as day, month, year -- that provide additional opportunities to aggregate the data.  
3.We will want to add a calculated field for length of ride since the 2020Q1 data did not have the "tripduration" column. We will add "ride_length" to the entire dataframe for consistency.  
4.There are some rides where tripduration shows up as negative, including several hundred rides where Divvy took bikes out of circulation for Quality Control reasons. We will want to delete these rides.


In the "member_casual" column, replace "Subscriber" with "member" and "Customer" with "casual"  
Before 2020, Divvy used different labels for these two types of riders ... we will want to make our dataframe consistent with their current nomenclature  
N.B.: "Level" is a special property of a column that is retained even if a subset does not contain any values from a specific level  
Begin by seeing how many observations fall under each usertype

```{r member_casual distinct values count}
table(all_trips$member_casual)
```
```{r member_casual update to two values, casual and member}
all_trips <-  all_trips %>% 
  mutate(member_casual = recode(member_casual
                           ,"Subscriber" = "member"
                           ,"Customer" = "casual"))
```

Check to make sure the proper number of observations were reassigned
```{r Checking if the values are reassigned to two categories}
table(all_trips$member_casual)
```

Now coming to second, let's add columns that list the date, month, day, and year of each ride  
This will allow us to aggregate ride data for each month, day, or year ... before completing these operations we could only aggregate at the ride level
<https://www.statmethods.net/input/dates.html> more on date formats in R found at that link

```{r Adding new columns, date, month, day, year}
all_trips$date <- as.Date(all_trips$started_at) #The default format is yyyy-mm-dd
all_trips$month <- format(as.Date(all_trips$date), "%m")
all_trips$day <- format(as.Date(all_trips$date), "%d")
all_trips$year <- format(as.Date(all_trips$date), "%Y")
all_trips$day_of_week <- format(as.Date(all_trips$date), "%A")
```

Coming to the third, Add a "ride_length" calculation to all_trips (in seconds)
<https://stat.ethz.ch/R-manual/R-devel/library/base/html/difftime.html>

```{r Adding calculated field ride_length}
all_trips$ride_length <- difftime(all_trips$ended_at,all_trips$started_at)
```

Let's inspect the structure of the columns now.
```{r Inspecting updated structure}
# Inspect the structure of the columns
str(all_trips)
```

Let's Convert "ride_length" from Factor to numeric so we can run calculations on the data
```{r Converting type of ride_length}
is.factor(all_trips$ride_length)
all_trips$ride_length <- as.numeric(as.character(all_trips$ride_length))
is.numeric(all_trips$ride_length)
```

Coming to the fourth one, Remove "bad" data  
The dataframe includes a few hundred entries when bikes were taken out of docks and checked for quality by Divvy or ride_length was negative  
We will create a new version of the dataframe (v2) since data is being removed
<https://www.datasciencemadesimple.com/delete-or-drop-rows-in-r-with-conditions-2/>
```{r removing bad data}
all_trips_v2 <- all_trips[!(all_trips$start_station_name == "HQ QR" | all_trips$ride_length<0),]
```

### Step-4 : DESCRIPTIVE DATA ANALYSIS

Descriptive analysis on ride_length (all figures in seconds)

```{r Descriptive analysis on ride_length}
mean(all_trips_v2$ride_length) #straight average (total ride length / rides)
median(all_trips_v2$ride_length) #midpoint number in the ascending array of ride lengths
max(all_trips_v2$ride_length) #longest ride
min(all_trips_v2$ride_length) #shortest ride
```

We can condense the four lines above to one line using summary() on the specific attribute
```{r Summary}
summary(all_trips_v2$ride_length)
```

Let's Compare members and casual users
```{r Comparing members and casual on different descriptive parameters}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = mean)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = median)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = max)
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual, FUN = min)
```

See the average ride time by each day for members vs casual users
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

Notice that the days of the week are out of order. Let's fix that.
```{r}
all_trips_v2$day_of_week <- ordered(all_trips_v2$day_of_week, levels=c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

Now, let's run the average ride time by each day for members vs casual users again
```{r}
aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
```

Let's analyze ridership data by type and weekday
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>%  #creates weekday field using wday()
  group_by(member_casual, weekday) %>%  #groups by usertype and weekday
  summarise(number_of_rides = n()							#calculates the number of rides and average duration 
  ,average_duration = mean(ride_length)) %>% 		# calculates the average duration
  arrange(member_casual, weekday)								# sorts
```


Let's visualize the number of rides by rider type
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = number_of_rides, fill = member_casual)) +
  geom_col(position = "dodge")

```

Let's create a visualization for average duration
```{r}
all_trips_v2 %>% 
  mutate(weekday = wday(started_at, label = TRUE)) %>% 
  group_by(member_casual, weekday) %>% 
  summarise(number_of_rides = n()
            ,average_duration = mean(ride_length)) %>% 
  arrange(member_casual, weekday)  %>% 
  ggplot(aes(x = weekday, y = average_duration, fill = member_casual)) +
  geom_col(position = "dodge")
```

### Step-5 : EXPORT SUMMARY FILE FOR FURTHER ANALYSIS
Create a csv file that we will visualize in Excel, Tableau, or my presentation software  
You can read more here: <https://datatofish.com/export-dataframe-to-csv-in-r/>

```{r}
counts <- aggregate(all_trips_v2$ride_length ~ all_trips_v2$member_casual + all_trips_v2$day_of_week, FUN = mean)
write.csv(counts, file = 'C:/Users/abhay/OneDrive/Desktop/Google Data Analytics/Capstone Project - Cyclist/avg_ride_length.csv')
```